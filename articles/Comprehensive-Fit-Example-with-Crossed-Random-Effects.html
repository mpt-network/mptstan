<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Comprehensive Fit Example with Crossed-Random Effects • mptstan</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Comprehensive Fit Example with Crossed-Random Effects">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">mptstan</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/Comprehensive-Fit-Example-with-Crossed-Random-Effects.html">Comprehensive Fit Example with Crossed-Random Effects</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Comprehensive Fit Example with Crossed-Random Effects</h1>
            
      

      <div class="d-none name"><code>Comprehensive-Fit-Example-with-Crossed-Random-Effects.Rmd</code></div>
    </div>

    
    
<p>We begin the analysis by loading <code>mptstan</code>. We then use
<code><a href="https://rdrr.io/r/base/options.html" class="external-link">options()</a></code> to auto-detect the numbers of cores and ensure
fitting uses multiple cores.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mpt-network.github.io/mptstan/">mptstan</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>mc.cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We show the analysis of a recognition memory data set (from Singmann,
Kellen, &amp; Klauer, 2013) using the unsure-extended 2-high threshold
model to a dataset investigating the other-race effect (i.e., a study
with two different types of old and new items, own-race faces and
other-race faces). This data is available in <code>mptstan</code> as
<code>skk13</code>. We will analyse this data using crossed-random
effects for participants and items.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">skk13</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    8400 obs. of  7 variables:</span></span>
<span><span class="co">#&gt;  $ id   : Factor w/ 42 levels "1","3","5","6",..: 1 1 1 1 1 1 1 1 1 1 ...</span></span>
<span><span class="co">#&gt;  $ trial: Factor w/ 200 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...</span></span>
<span><span class="co">#&gt;  $ race : Factor w/ 2 levels "german","arabic": 2 1 1 1 1 1 1 2 1 1 ...</span></span>
<span><span class="co">#&gt;  $ type : Factor w/ 2 levels "old","new": 1 1 2 2 1 1 1 1 2 2 ...</span></span>
<span><span class="co">#&gt;  $ resp : Factor w/ 3 levels "old","unsure",..: 3 1 3 1 1 1 3 1 3 3 ...</span></span>
<span><span class="co">#&gt;  $ rt   : num  4.68 2.75 4.25 1.6 0.95 ...</span></span>
<span><span class="co">#&gt;  $ stim : Factor w/ 200 levels "A001","A002",..: 40 132 117 143 140 162 193 19 120 170 ...</span></span></code></pre></div>
<p>Because we want the MPT model parameters to differ across the
<code>race</code> factor in the data (i.e., the race of the
to-be-recognised face), we set contrasts appropriate for Bayesian models
for the current <code>R</code> session using
<code>options(contrasts = ...)</code>. In particular, we use the
contrasts proposed by Rouder et al. (2012) that guarantee two things:
(a) contrasts sum to zero: for each factor/coefficient, 0 corresponds to
the mean value and not to a specific factor level. Consequently, these
contrasts are appropriate for models that include interactions. (b)
contrasts have the same marginal priors for each factor level. These
priors are available in package <code>bayestestR</code> as
<code>contr.equalprior</code>. (Note that setting contrasts using
<code><a href="https://rdrr.io/r/base/options.html" class="external-link">options()</a></code> affect most regression functions in
<code>R</code>, such as <code>lm</code> and <code>lmer</code>.)</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://easystats.github.io/bayestestR/" class="external-link">"bayestestR"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>contrasts<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">'contr.sum'</span>, <span class="st">'contr.equalprior'</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="step-1-create-mpt-model-object">Step 1: Create MPT Model Object<a class="anchor" aria-label="anchor" href="#step-1-create-mpt-model-object"></a>
</h3>
<p>The first step when using <code>mptstan</code> is the creation of a
MPT model object using <code><a href="../reference/make_mpt.html">make_mpt()</a></code> (which creates an object
of class <code>mpt_model</code>).</p>
<p><code><a href="../reference/make_mpt.html">make_mpt()</a></code> can read MPT models in both the commonly used
<code>EQN</code> model format (e.g., used by <code>TreeBUGS</code>) and
the <code>easy</code> format introduced by <code>MPTinR</code>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For the easy EQN format, we just need the EQN file location:</span></span>
<span><span class="va">EQNFILE</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">"extdata"</span>, <span class="st">"u2htm.eqn"</span>, package <span class="op">=</span> <span class="st">"mptstan"</span><span class="op">)</span></span>
<span><span class="va">u2htsm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/make_mpt.html">make_mpt</a></span><span class="op">(</span><span class="va">EQNFILE</span><span class="op">)</span> <span class="co">## make_mpt() auto-detects EQN files from name</span></span>
<span><span class="co">#&gt; model type auto-detected as 'eqn'</span></span>
<span><span class="co">#&gt; Warning: parameter names ending with a number amended with 'x'</span></span>
<span><span class="va">u2htsm_model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; MPT model with 4 independent categories (from 2 trees) and 4 parameters:</span></span>
<span><span class="co">#&gt;   Dn, Do, g1x, g2x</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Tree 1: old</span></span>
<span><span class="co">#&gt;   Categories: old, unsure, new </span></span>
<span><span class="co">#&gt;   Parameters: Do, g1x, g2x</span></span>
<span><span class="co">#&gt; Tree 2: new</span></span>
<span><span class="co">#&gt;   Categories: old, unsure, new </span></span>
<span><span class="co">#&gt;   Parameters: Dn, g1x, g2x</span></span>
<span></span>
<span><span class="co">## Alternatively, we can just enter the equations and use the easy format.</span></span>
<span><span class="va">u2htm</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st"># Old Items</span></span>
<span><span class="st">Do + (1 - Do) * (1 - g1) * g2</span></span>
<span><span class="st">(1 - Do) * g1</span></span>
<span><span class="st">(1 - Do) * (1 - g1) * (1 - g2)</span></span>
<span><span class="st"></span></span>
<span><span class="st"># New Items</span></span>
<span><span class="st">(1 - Dn) * (1 - g1) * g2</span></span>
<span><span class="st">(1 - Dn) * g1</span></span>
<span><span class="st">Dn + (1 - Dn) * (1 - g1) * (1 - g2)</span></span>
<span><span class="st">"</span></span>
<span><span class="co"># for the easy format, we need to specify tree names and category names</span></span>
<span><span class="va">u2htsm_model_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/make_mpt.html">make_mpt</a></span><span class="op">(</span>text <span class="op">=</span> <span class="va">u2htm</span>, </span>
<span>                           trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"old"</span>, <span class="st">"new"</span><span class="op">)</span>,</span>
<span>                           categories <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"old"</span>, <span class="st">"unsure"</span>, <span class="st">"new"</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: parameter names ending with a number amended with 'x'</span></span>
<span><span class="va">u2htsm_model_2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; MPT model with 4 independent categories (from 2 trees) and 4 parameters:</span></span>
<span><span class="co">#&gt;   Dn, Do, g1x, g2x</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Tree 1: old</span></span>
<span><span class="co">#&gt;   Categories: old, unsure, new </span></span>
<span><span class="co">#&gt;   Parameters: Do, g1x, g2x</span></span>
<span><span class="co">#&gt; Tree 2: new</span></span>
<span><span class="co">#&gt;   Categories: old, unsure, new </span></span>
<span><span class="co">#&gt;   Parameters: Dn, g1x, g2x</span></span></code></pre></div>
<p>As shown in the output, if a model parameter ends with a number,
<code>mptstan</code> adds an <code>x</code> to the parameter name (as
<code>brms</code> cannot handle custom parameters ending with a number).
If a model already has a parameter with this name (i.e., the original
parameter name ending with a number plus x) this might leave to problems
and should be avoided.</p>
</div>
<div class="section level3">
<h3 id="step-2-create-formula-optional">Step 2: Create Formula (Optional)<a class="anchor" aria-label="anchor" href="#step-2-create-formula-optional"></a>
</h3>
<p>The second and optional step is creating an MPT formula object with
<code><a href="../reference/mpt_formula.html">mpt_formula()</a></code>. Here, we show the case in which the same
formula applies to all MPT model parameters. In this case, we specify
only a single formula and also need to pass the MPT model object (as the
<code>model</code> argument).</p>
<p>In the formula, the left-hand-side specifies the response variable
(in the present case <code>resp</code>) and the right-hand side
specifies the fixed-effect regression coefficients and random-effect
(i.e., multilevel) structure using the <code>brms</code>-extended
<code>lme4</code> syntax. Here, we have one fixed-effect, for the
<code>race</code> factor. Furthermore, we have both by-participant and
by-item random-effect terms. For the by-participant random-effect term
we estimate both random intercepts and random slopes for
<code>race</code> (as <code>race</code> is a within-participants
factor). For the by-item random-effect term we only estimate random
intercepts. For both random-effect terms we add a unique identifier
between the regression structure for the random-effect term (i.e.,
<code>race</code> or <code>1</code>) and the grouping factor (i.e.,
<code>id</code> and <code>stim</code>), <code>p</code> for participants
and <code>i</code> for items. These identifiers ensures that
random-effect correlations are estimated across MPT model parameters. In
other words, these identifiers ensure that for each random-effect term
the full correlation matrix across all MPT model parameters is estimated
in line with Klauer’s (2010) latent trait approach.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">u2htm_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mpt_formula.html">mpt_formula</a></span><span class="op">(</span><span class="va">resp</span> <span class="op">~</span> <span class="va">race</span> <span class="op">+</span> <span class="op">(</span><span class="va">race</span><span class="op">|</span><span class="va">p</span><span class="op">|</span><span class="va">id</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span><span class="op">|</span><span class="va">i</span><span class="op">|</span><span class="va">stim</span><span class="op">)</span>, </span>
<span>                             model <span class="op">=</span> <span class="va">u2htsm_model</span><span class="op">)</span></span>
<span><span class="va">u2htm_formula</span></span>
<span><span class="co">#&gt; MPT formulas for long / non-aggregated data (response: resp):</span></span>
<span><span class="co">#&gt; Dn ~ race + (race | p | id) + (1 | i | stim)</span></span>
<span><span class="co">#&gt; Do ~ race + (race | p | id) + (1 | i | stim)</span></span>
<span><span class="co">#&gt; g1x ~ race + (race | p | id) + (1 | i | stim)</span></span>
<span><span class="co">#&gt; g2x ~ race + (race | p | id) + (1 | i | stim)</span></span></code></pre></div>
<p>As shown in the output, if we specify a MPT model formula with only a
single formula, this formula applies to all MPT model parameters. In
this case, using <code><a href="../reference/mpt_formula.html">mpt_formula()</a></code> is optional and we could
also specify the formula as the first argument of the fitting function,
<code><a href="../reference/mpt.html">mpt()</a></code>.</p>
<p>Creating a formula object is not optional if you want to specify an
individual and potentially different formula for each MPT model
parameter. In this case, the left-hand-side of each formula needs to
specify the MPT model parameter and the response variable needs to be
specified via the <code>response</code> argument. For examples, see
<code><a href="../reference/mpt_formula.html">?mpt_formula</a></code>.</p>
</div>
<div class="section level3">
<h3 id="step-3-fit-model">Step 3: Fit Model<a class="anchor" aria-label="anchor" href="#step-3-fit-model"></a>
</h3>
<p>With the MPT model object and model formula we are ready to fit the
MPT model. For this, we use function <code><a href="../reference/mpt.html">mpt()</a></code> which in
addition to the two aforementioned objects requires the data as well as
the variable in the data distinguishing to which tree (or data type) a
particular response belongs. In the present case that is the
<code>type</code> variable. (The tree variable can only be omitted in
case the model consists of solely one tree.)</p>
<p>In addition to the required arguments (model object, formula, data,
and tree variable), we can pass further arguments to
<code><a href="https://paulbuerkner.com/brms/reference/brm.html" class="external-link">brms::brm()</a></code> and onward to <code><a href="https://mc-stan.org/rstan/reference/stan.html" class="external-link">rstan::stan()</a></code>, which
ultimately performs the MCMC sampling. Here, we also pass
<code>init_r = 0.5</code> which ensures that the random start values are
drawn from a uniform distribution ranging from -0.5 to 0.5 (instead of
the default -2 to 2). Our testing has shown that with
<code>init_r = 0.5</code> MPT models with random-effect terms are much
less likely to fail initialisation. We could pass further arguments such
as <code>chains</code>, <code>warmup</code>, <code>iter</code>, or
<code>thin</code> to control the MCMC sampling.</p>
<p>Note that fitting this model can take up to an an hour or longer
(depending on your computer).</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_skk</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mpt.html">mpt</a></span><span class="op">(</span><span class="va">u2htm_formula</span>, data <span class="op">=</span> <span class="va">skk13</span>,</span>
<span>               tree <span class="op">=</span> <span class="st">"type"</span>,</span>
<span>               init_r <span class="op">=</span> <span class="fl">0.5</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span></span>
<span><span class="co">#&gt; Running the chains for more iterations may help. See</span></span>
<span><span class="co">#&gt; https://mc-stan.org/misc/warnings.html#bulk-ess</span></span>
<span><span class="co">#&gt; Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span></span>
<span><span class="co">#&gt; Running the chains for more iterations may help. See</span></span>
<span><span class="co">#&gt; https://mc-stan.org/misc/warnings.html#tail-ess</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="step-4-post-processing">Step 4: Post-Processing<a class="anchor" aria-label="anchor" href="#step-4-post-processing"></a>
</h3>
<p><code>mptstan</code> uses <code><a href="https://paulbuerkner.com/brms/reference/brm.html" class="external-link">brms::brm()</a></code> for model
estimation and returns a <code>brmsfit</code> object. As a consequence,
the full post-processing functionality of <code>brms</code> and
associated packages is available (e.g., <code>emmeans</code>,
<code>tidybayes</code>). However, for the time being
<code>mptstan</code> does not contain many MPT-specific post-processing
functionality with the exception of <code>mpt_emmeans</code> as
introduced below. Thus, the <code>brms</code> post-processing
functionality is mostly what is available. Whereas this functionality is
rather sophisticated and flexible, it is not always perfect for MPT
models with many parameters.</p>
<p>When inspecting post-processing output from <code>brms</code>, the
most important thing to understand is that <code>brms</code> does not
label the first parameter in a model (i.e., as shown in the model
object). For example, the model parameter <code>Intercept</code> refers
to the intercept of the first MPT model parameter (i.e., <code>Dn</code>
in the present case). All other parameters are labelled with the
corresponding MPT model parameter name, but not the first MPT model
parameter.</p>
<p>The default <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> method for <code>brms</code>
objects first lists the estimates for the random-effects terms and then
the estimates of the fixed-effects regression coefficients. As mentioned
in the previous paragraphs, all estimates have a label clarifying which
MPT model parameter they refer to with the exception of estimates
referring to the first MPT model parameter, here <code>Dn</code>.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_skk</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: mpt </span></span>
<span><span class="co">#&gt;   Links: mu = probit; Do = probit; g1x = probit; g2x = probit </span></span>
<span><span class="co">#&gt; Formula: resp ~ race + (race | p | id) + (1 | i | stim) </span></span>
<span><span class="co">#&gt;          Do ~ race + (race | p | id) + (1 | i | stim)</span></span>
<span><span class="co">#&gt;          g1x ~ race + (race | p | id) + (1 | i | stim)</span></span>
<span><span class="co">#&gt;          g2x ~ race + (race | p | id) + (1 | i | stim)</span></span>
<span><span class="co">#&gt;    Data: structure(list(id = structure(c(1L, 1L, 1L, 1L, 1L (Number of observations: 8400) </span></span>
<span><span class="co">#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span></span>
<span><span class="co">#&gt;          total post-warmup draws = 4000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multilevel Hyperparameters:</span></span>
<span><span class="co">#&gt; ~id (Number of levels: 42) </span></span>
<span><span class="co">#&gt;                                  Estimate Est.Error l-95% CI u-95% CI Rhat</span></span>
<span><span class="co">#&gt; sd(Intercept)                        0.78      0.18     0.48     1.20 1.01</span></span>
<span><span class="co">#&gt; sd(race1)                            0.11      0.09     0.00     0.33 1.01</span></span>
<span><span class="co">#&gt; sd(Do_Intercept)                     0.56      0.09     0.41     0.75 1.00</span></span>
<span><span class="co">#&gt; sd(Do_race1)                         0.09      0.05     0.01     0.21 1.01</span></span>
<span><span class="co">#&gt; sd(g1x_Intercept)                    1.06      0.15     0.81     1.41 1.00</span></span>
<span><span class="co">#&gt; sd(g1x_race1)                        0.15      0.05     0.07     0.25 1.00</span></span>
<span><span class="co">#&gt; sd(g2x_Intercept)                    0.54      0.09     0.38     0.74 1.00</span></span>
<span><span class="co">#&gt; sd(g2x_race1)                        0.24      0.06     0.14     0.36 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,race1)                -0.04      0.33    -0.66     0.62 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,Do_Intercept)          0.44      0.17     0.07     0.73 1.00</span></span>
<span><span class="co">#&gt; cor(race1,Do_Intercept)             -0.07      0.32    -0.64     0.59 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,Do_race1)              0.05      0.29    -0.53     0.60 1.00</span></span>
<span><span class="co">#&gt; cor(race1,Do_race1)                 -0.06      0.33    -0.66     0.58 1.00</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,Do_race1)           0.19      0.30    -0.44     0.71 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,g1x_Intercept)        -0.02      0.21    -0.41     0.41 1.01</span></span>
<span><span class="co">#&gt; cor(race1,g1x_Intercept)            -0.02      0.33    -0.65     0.62 1.02</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g1x_Intercept)      0.02      0.16    -0.30     0.35 1.01</span></span>
<span><span class="co">#&gt; cor(Do_race1,g1x_Intercept)         -0.21      0.28    -0.66     0.41 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,g1x_race1)            -0.17      0.24    -0.62     0.33 1.00</span></span>
<span><span class="co">#&gt; cor(race1,g1x_race1)                -0.06      0.32    -0.66     0.56 1.00</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g1x_race1)          0.26      0.21    -0.18     0.66 1.00</span></span>
<span><span class="co">#&gt; cor(Do_race1,g1x_race1)             -0.02      0.31    -0.61     0.58 1.00</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g1x_race1)         0.28      0.25    -0.26     0.71 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,g2x_Intercept)        -0.43      0.19    -0.77    -0.02 1.01</span></span>
<span><span class="co">#&gt; cor(race1,g2x_Intercept)             0.04      0.32    -0.58     0.64 1.00</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g2x_Intercept)      0.02      0.18    -0.32     0.38 1.00</span></span>
<span><span class="co">#&gt; cor(Do_race1,g2x_Intercept)          0.03      0.29    -0.54     0.59 1.00</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g2x_Intercept)     0.19      0.19    -0.20     0.52 1.01</span></span>
<span><span class="co">#&gt; cor(g1x_race1,g2x_Intercept)         0.25      0.24    -0.22     0.69 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,g2x_race1)             0.32      0.21    -0.14     0.69 1.00</span></span>
<span><span class="co">#&gt; cor(race1,g2x_race1)                 0.12      0.34    -0.55     0.71 1.01</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g2x_race1)          0.16      0.19    -0.23     0.52 1.00</span></span>
<span><span class="co">#&gt; cor(Do_race1,g2x_race1)              0.15      0.30    -0.47     0.69 1.01</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g2x_race1)         0.13      0.21    -0.29     0.53 1.00</span></span>
<span><span class="co">#&gt; cor(g1x_race1,g2x_race1)            -0.16      0.27    -0.65     0.38 1.00</span></span>
<span><span class="co">#&gt; cor(g2x_Intercept,g2x_race1)        -0.12      0.22    -0.54     0.32 1.00</span></span>
<span><span class="co">#&gt;                                  Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sd(Intercept)                        1114     1903</span></span>
<span><span class="co">#&gt; sd(race1)                             862     2017</span></span>
<span><span class="co">#&gt; sd(Do_Intercept)                     1601     2373</span></span>
<span><span class="co">#&gt; sd(Do_race1)                          608     1192</span></span>
<span><span class="co">#&gt; sd(g1x_Intercept)                    1769     2106</span></span>
<span><span class="co">#&gt; sd(g1x_race1)                        1927     1821</span></span>
<span><span class="co">#&gt; sd(g2x_Intercept)                     776     1791</span></span>
<span><span class="co">#&gt; sd(g2x_race1)                         808     1606</span></span>
<span><span class="co">#&gt; cor(Intercept,race1)                 3807     2430</span></span>
<span><span class="co">#&gt; cor(Intercept,Do_Intercept)          1042     1701</span></span>
<span><span class="co">#&gt; cor(race1,Do_Intercept)               423      898</span></span>
<span><span class="co">#&gt; cor(Intercept,Do_race1)              3241     2495</span></span>
<span><span class="co">#&gt; cor(race1,Do_race1)                  1350     2299</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,Do_race1)           2825     2447</span></span>
<span><span class="co">#&gt; cor(Intercept,g1x_Intercept)          457     1061</span></span>
<span><span class="co">#&gt; cor(race1,g1x_Intercept)              192      301</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g1x_Intercept)       998     1948</span></span>
<span><span class="co">#&gt; cor(Do_race1,g1x_Intercept)           416      586</span></span>
<span><span class="co">#&gt; cor(Intercept,g1x_race1)             2180     2803</span></span>
<span><span class="co">#&gt; cor(race1,g1x_race1)                  686     1955</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g1x_race1)          3188     3305</span></span>
<span><span class="co">#&gt; cor(Do_race1,g1x_race1)              1255     2886</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g1x_race1)         3506     3328</span></span>
<span><span class="co">#&gt; cor(Intercept,g2x_Intercept)          768     1832</span></span>
<span><span class="co">#&gt; cor(race1,g2x_Intercept)              595     1128</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g2x_Intercept)      1788     2546</span></span>
<span><span class="co">#&gt; cor(Do_race1,g2x_Intercept)           935     1664</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g2x_Intercept)      810     2139</span></span>
<span><span class="co">#&gt; cor(g1x_race1,g2x_Intercept)         1410     2385</span></span>
<span><span class="co">#&gt; cor(Intercept,g2x_race1)             1072     1867</span></span>
<span><span class="co">#&gt; cor(race1,g2x_race1)                  418     1189</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g2x_race1)          2379     3131</span></span>
<span><span class="co">#&gt; cor(Do_race1,g2x_race1)               727     1226</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g2x_race1)         1181     2442</span></span>
<span><span class="co">#&gt; cor(g1x_race1,g2x_race1)             1710     2484</span></span>
<span><span class="co">#&gt; cor(g2x_Intercept,g2x_race1)         1510     2899</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ~stim (Number of levels: 200) </span></span>
<span><span class="co">#&gt;                                  Estimate Est.Error l-95% CI u-95% CI Rhat</span></span>
<span><span class="co">#&gt; sd(Intercept)                        0.88      0.14     0.63     1.20 1.00</span></span>
<span><span class="co">#&gt; sd(Do_Intercept)                     0.43      0.06     0.33     0.55 1.01</span></span>
<span><span class="co">#&gt; sd(g1x_Intercept)                    0.06      0.04     0.00     0.15 1.00</span></span>
<span><span class="co">#&gt; sd(g2x_Intercept)                    0.42      0.06     0.30     0.55 1.01</span></span>
<span><span class="co">#&gt; cor(Intercept,Do_Intercept)          0.31      0.17    -0.01     0.63 1.01</span></span>
<span><span class="co">#&gt; cor(Intercept,g1x_Intercept)        -0.15      0.39    -0.82     0.65 1.00</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g1x_Intercept)     -0.25      0.40    -0.88     0.62 1.00</span></span>
<span><span class="co">#&gt; cor(Intercept,g2x_Intercept)        -0.43      0.22    -0.81    -0.01 1.01</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g2x_Intercept)     -0.05      0.19    -0.39     0.32 1.02</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g2x_Intercept)    -0.07      0.41    -0.79     0.75 1.02</span></span>
<span><span class="co">#&gt;                                  Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; sd(Intercept)                        1215     1861</span></span>
<span><span class="co">#&gt; sd(Do_Intercept)                      819     1611</span></span>
<span><span class="co">#&gt; sd(g1x_Intercept)                     971     1892</span></span>
<span><span class="co">#&gt; sd(g2x_Intercept)                     436     1067</span></span>
<span><span class="co">#&gt; cor(Intercept,Do_Intercept)           423      913</span></span>
<span><span class="co">#&gt; cor(Intercept,g1x_Intercept)         2908     2313</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g1x_Intercept)      2597     2648</span></span>
<span><span class="co">#&gt; cor(Intercept,g2x_Intercept)          296      773</span></span>
<span><span class="co">#&gt; cor(Do_Intercept,g2x_Intercept)       507     1200</span></span>
<span><span class="co">#&gt; cor(g1x_Intercept,g2x_Intercept)      119      279</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Regression Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span><span class="co">#&gt; Intercept        -0.55      0.22    -1.00    -0.17 1.01      746     1605</span></span>
<span><span class="co">#&gt; Do_Intercept      0.14      0.11    -0.08     0.35 1.01      839     1780</span></span>
<span><span class="co">#&gt; g1x_Intercept    -1.35      0.17    -1.71    -1.01 1.00     1420     2100</span></span>
<span><span class="co">#&gt; g2x_Intercept    -0.38      0.12    -0.62    -0.15 1.00      852     2367</span></span>
<span><span class="co">#&gt; race1             0.37      0.12     0.15     0.60 1.00     1312     2034</span></span>
<span><span class="co">#&gt; Do_race1          0.01      0.05    -0.09     0.11 1.00     1775     2505</span></span>
<span><span class="co">#&gt; g1x_race1        -0.06      0.04    -0.15     0.03 1.00     2877     3014</span></span>
<span><span class="co">#&gt; g2x_race1        -0.13      0.07    -0.27     0.01 1.00     1264     2532</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS</span></span>
<span><span class="co">#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span></span>
<span><span class="co">#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span></span></code></pre></div>
<p>Typically the primary interest is in the fixed-effect regression
coefficients which can be found in the table labelled “Regression
Coefficients”. Some of these estimates are smaller than zero or larger
than one, which is not possible for MPT parameter estimates (which are
on the probability scale). The reason for such values is that the
estimates are shown on the unconstrained or linear – that is, probit –
scale.</p>
<p>Looking at the table of regression coefficients we see two different
types of estimates for each of the four MPT model parameters, four
intercepts and four slopes for the effect of race (recall that estimates
without a parameter label are for the <code>Dn</code> parameter). When
inspecting the four slopes in more detail we can see that only for one
of the slopes, the <code>race1</code> coefficient for the
<code>Dn</code> parameter, does the 95% CI not include 0. This indicates
that there is evidence that <code>Dn</code> differs for the two
different types of face stimuli (i.e., German versus Arabic faces). This
finding is in line with the results reported in Singmann et al. (2013).
Hence, even though the table of regression coefficients is on the probit
scale, we can in situations such as the present one still derive
meaningful conclusions from it.</p>
<p>One way to obtain the estimates on the MPT parameter scale is by
using package <code>emmeans</code>. <code>mptstan</code> comes with a
convenience wrapper to <code>emmeans</code>, called
<code><a href="../reference/mpt_emmeans.html">mpt_emmeans()</a></code>, which provides output for each MPT model
parameter simultaneously but otherwise works exactly like the
<code>emmeans()</code> function:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/mpt_emmeans.html">mpt_emmeans</a></span><span class="op">(</span><span class="va">fit_skk</span>, <span class="st">"race"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   parameter   race   response  lower.HPD upper.HPD</span></span>
<span><span class="co">#&gt; 1        Dn german 0.43305661 0.24889660 0.5938111</span></span>
<span><span class="co">#&gt; 2        Dn arabic 0.18455338 0.06265918 0.3093766</span></span>
<span><span class="co">#&gt; 3        Do german 0.56213484 0.46394103 0.6510327</span></span>
<span><span class="co">#&gt; 4        Do arabic 0.55176900 0.46281825 0.6424701</span></span>
<span><span class="co">#&gt; 5       g1x german 0.08032168 0.03225784 0.1407091</span></span>
<span><span class="co">#&gt; 6       g1x arabic 0.09857215 0.04504090 0.1602572</span></span>
<span><span class="co">#&gt; 7       g2x german 0.30406461 0.20843582 0.4077200</span></span>
<span><span class="co">#&gt; 8       g2x arabic 0.39994499 0.30632449 0.5048775</span></span></code></pre></div>
<p>We can also use the special syntax <code>"1"</code> to get the
overall mean estimate for each parameter. Note that, because of the
non-linear probit transformation, this might be different from the means
of the marginal means.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/mpt_emmeans.html">mpt_emmeans</a></span><span class="op">(</span><span class="va">fit_skk</span>, <span class="st">"1"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   parameter      X1   response  lower.HPD upper.HPD</span></span>
<span><span class="co">#&gt; 1        Dn overall 0.29757056 0.15962015 0.4325167</span></span>
<span><span class="co">#&gt; 2        Do overall 0.55653868 0.47342278 0.6399529</span></span>
<span><span class="co">#&gt; 3       g1x overall 0.08928845 0.04009512 0.1488125</span></span>
<span><span class="co">#&gt; 4       g2x overall 0.35150225 0.26724324 0.4370866</span></span></code></pre></div>
<p>Another MPT model specific function is <code><a href="../reference/ppp_test.html">ppp_test()</a></code>, which
calculate a posterior predictive
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value
to test a model’s fit. More specifically, the function currently
implements the T1-test statistic of Klauer (2010). If the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value
is small, say smaller than .05, this indicates an insufficient fit or
model misfit – in other words, a significant divergence of the observed
data from the data that would be expected to arise if the fitted model
were the data generating model.</p>
<p>In the present case the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value
is clearly large (i.e., near .5) indicating an adequate model fit. Given
that the unsure-extended 2-high threshold model is a saturated MPT model
(with number of parameters equal to number of independent categories),
such a good fit is probably not too surprising.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/ppp_test.html">ppp_test</a></span><span class="op">(</span><span class="va">fit_skk</span><span class="op">)</span></span>
<span><span class="co">#&gt;  ## Mean structure (T1):</span></span>
<span><span class="co">#&gt;  Observed =  3.293324 ; Predicted =  3.210767 ; p-value =  0.491</span></span></code></pre></div>
<p>As mentioned above, <code>mptstan</code> also provides full
integration for <code>brms</code> post-processing.</p>
<p>For example, we can obtain graphical posterior predictive checks
using <code><a href="https://mc-stan.org/bayesplot/reference/pp_check.html" class="external-link">pp_check()</a></code>. For MPT models,
<code>type = "bars_grouped"</code> provides a helpful plot if we
additional pass <code>group = "mpt_tree"</code> (which creates one panel
per tree). We can also change the x-axis labels to match the response
categories.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html" class="external-link">pp_check</a></span><span class="op">(</span><span class="va">fit_skk</span>, type <span class="op">=</span> <span class="st">"bars_grouped"</span>, group <span class="op">=</span> <span class="st">"mpt_tree"</span>, ndraws <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"old"</span>, <span class="st">"unsure"</span>, <span class="st">"new"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Scale for <span style="color: #00BB00;">x</span> is already present.</span></span>
<span><span class="co">#&gt; Adding another scale for <span style="color: #00BB00;">x</span>, which will replace the existing scale.</span></span></code></pre></div>
<p><img src="Comprehensive-Fit-Example-with-Crossed-Random-Effects_files/figure-html/unnamed-chunk-11-1.png" width="672">
In addition, we can directly obtain information criteria such as loo or
get posterior mean/expectation predictions for each observation.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">loo_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html" class="external-link">loo</a></span><span class="op">(</span><span class="va">fit_skk</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 4000 by 8400 log-likelihood matrix.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate    SE</span></span>
<span><span class="co">#&gt; elpd_loo  -5678.4  63.0</span></span>
<span><span class="co">#&gt; p_loo       459.7   7.7</span></span>
<span><span class="co">#&gt; looic     11356.8 126.0</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; MCSE of elpd_loo is 0.4.</span></span>
<span><span class="co">#&gt; MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.8]).</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.7).</span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="va">pepred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_epred.html" class="external-link">posterior_epred</a></span><span class="op">(</span><span class="va">fit_skk</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">pepred</span><span class="op">)</span> <span class="co">## [sample, observation, response category]</span></span>
<span><span class="co">#&gt;  num [1:4000, 1:8400, 1:3] 0.367 0.413 0.381 0.364 0.496 ...</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="priors">Priors<a class="anchor" aria-label="anchor" href="#priors"></a>
</h3>
<p><code>mptstan</code> comes with default priors for the fixed-effect
regression coefficients. For the intercepts, it uses a Normal(0, 1)
prior and for all non-intercept coefficients (i.e., slopes) Normal(0,
0.5) prior. These priors can be changed through the
<code>default_prior_intercept</code> and <code>default_prior_coef</code>
arguments (see <code><a href="../reference/mpt.html">?mpt</a></code>).</p>
<p>For the hierarchical structure, <code>mptstan</code> uses the
<code>brms</code> default priors.</p>
</div>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<ul>
<li>Klauer, K. C. (2010). Hierarchical Multinomial Processing Tree
Models: A Latent-Trait Approach. Psychometrika, 75(1), 70-98. <a href="https://doi.org/10.1007/s11336-009-9141-0" class="external-link uri">https://doi.org/10.1007/s11336-009-9141-0</a>
</li>
<li>Rouder, J. N., Morey, R. D., Speckman, P. L., &amp; Province, J. M.
(2012). Default Bayes factors for ANOVA designs. Journal of Mathematical
Psychology, 56(5), 356–374. <a href="https://doi.org/10.1016/j.jmp.2012.08.001" class="external-link uri">https://doi.org/10.1016/j.jmp.2012.08.001</a>
</li>
<li>Singmann, H., Kellen, D., &amp; Klauer, K. C. (2013). Investigating
the Other-Race Effect of Germans towards Turks and Arabs using
Multinomial Processing Tree Models. In M. Knauff, M. Pauen, N. Sebanz,
&amp; I. Wachsmuth (Eds.), Proceedings of the 35th Annual Conference of
the Cognitive Science Society (pp. 1330–1335). Austin, TX: Cognitive
Science Society. <a href="http://singmann.org/download/publications/SKK-CogSci2013.pdf" class="external-link uri">http://singmann.org/download/publications/SKK-CogSci2013.pdf</a>
</li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Henrik Singmann, Marie Jakob.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
